
# 爬虫学习使用指南

>Auth: 王海飞
>
>Data：2018-06-04
>
>Email：779598160@qq.com
>
>github：https://github.com/coco369/knowledge 


### 前言

网络爬虫（Web Spider。又被称为网页蜘蛛。网络机器人，又称为网页追逐者），是一种依照一定的规则，自己主动的抓取万维网信息的程序或者脚本。另外一些不常使用的名字还有蚂蚁，自己主动索引。模拟程序或者蠕虫。假设把互联网比喻成一个蜘蛛网，那么Spider就是在网上爬来爬去的蜘蛛。

网络蜘蛛是通过网页的链接地址来寻找网页的。从站点某一个页面（一般是首页）開始，读取网页的内容。找到在网页中的其他链接地址。然后通过这些链接地址寻找下一个网页。这样一直循环下去，直到把这个站点全部的网页都抓取完为止。假设把整个互联网当成一个站点。那么网络蜘蛛就能够用这个原理把互联网上全部的网页都抓取下来。这样看来，网络爬虫就是一个爬行程序，一个抓取网页的程序。

<b>简单地说，网络爬虫的基本任务就是抓取网页内容。</b>


### 1. 同步和异步、阻塞和非阻塞

案例：

故事：老王煮稀饭。

人物：老张，锅两个（普通锅，简称普锅；会响的高压锅，简称响锅）。

老王想了想，有好几种等待方式

1.老王用普锅煮稀饭，并且站在那里，不管稀饭开没开，每隔一定时间看看稀饭开了没。<b>－同步阻塞</b>

老王想了想，这种方法不够聪明。

2.老王还是用普锅煮稀饭，不再傻傻的站在那里看稀饭水开，跑去寝室上网，但是还是会每隔一段时间过来看看稀饭水开了没有，水没有开就走人。<b>－同步非阻塞</b>

老王想了想，现在的方法聪明了些，但是还是不够好。

3.老王这次使用高大上的响锅来煮稀饭，站在那里，但是不会再每隔一段时间去看水开，而是等水开了，水壶会自动的通知他。<b>－异步阻塞</b>

老王想了想，不会呀，既然响锅可以通知我，那我为什么还要傻傻的站在那里等呢，嗯，得换个方法。

4.老王还是使用响锅煮稀饭，跑到客厅上网去，等着响锅自己把水煮熟了以后通知他。<b>－异步非阻塞</b>

老王豁然，这下感觉轻松了很多。

#### 1.1 同步和异步

同步和异步是相对于操作结果来说，会不会等待结果

#### 1.2 阻塞和非阻塞

阻塞是在煮稀饭的过程中，你不能去干其他的事情。非阻塞是在煮稀饭的过程中，你还可以去做其他的事情。阻塞和非阻塞是相对于线程是否被阻塞


#### 1.3 同步和阻塞的区别

同步是一个过程，阻塞是线程的一个状态。

当多个线程操作同一公共变量的时候可能会出现竞争的情况，这时候需要使用同步来防止多个线程同时占用资源的情况，让一个线程在运行状态中，另外的线程处于就绪状态，当前一个线程处于暂停状态的时候，后面的处于就绪状态的线程，获取到资源以后，获取到时间片以后就会处于运行状态了。所以阻塞是线程的一个状态而已


### 2. 数据分析和采集

本爬虫教程中使用的python版本统一为python3.X的版本

#### 2.1 数据分析

爬取网页信息可以使用很多的技术：

1. 获取网页信息：urllib、urllib3、requests

		requests为第三方的库，需要安装才能使用

		pip install requests

2. 解析网页信息：beautifulsoup4(bs4)、re、xpath、lxml

		bs4为第三方的库，需要安装才能使用

		pip install beautifulsoup4

		使用的时候 from bs4 import BeautifulSoup 这样导入

	Python 标准库中自带了 xml 模块，但是性能不够好，而且缺乏一些人性化的 API，相比之下，第三方库 lxml 是用 Cython 实现的，而且增加了很多实用的功能。

		安装lxml
		
		pip install lxml

3. 动态数据解析

	通用：selenium(自动化测试框架)


#### 2.2 数据采集

4. 存储：mysql、redis、mongodb、sqlalchemy

5. 序列化：json

6. 调度器：进程、线程、协程


### 3. urllib3的使用

	 
	import urllib3
	
	# 你需要一个PoolManager实例来生成请求,由该实例对象处理与线程池的连接以及
	# 线程安全的所有细节，不需要任何人为操作
	http = urllib3.PoolManager()
	
	# request()方法创建一个GET请求去获取百度的网页信息，返回的r是一个HttpResponse对象
	r = http.request('GET', 'https://www.baidu.com')
	# 打印请求的状态
	print(r.status)
	
	# 打印请求网页的内容
	print(r.data)



